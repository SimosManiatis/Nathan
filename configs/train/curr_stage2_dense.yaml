env:
  width: 8
  height: 8
  max_width: 12
  max_height: 12
  dense_reward: true
  trap_density: 0.10
  max_steps_multiplier: 4

training:
  algo: "PPO"
  policy: "MultiInputPolicy"
  total_timesteps: 500000 
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  
  checkpoint_freq: 50000
  log_interval: 10

evaluation:
  eval_freq: 20000
  n_eval_episodes: 50
  benchmark_path: "configs/maps/benchmark_seeds.yaml"
