# PPO Training Configuration

env:
  width: 8
  height: 8
  trap_density: 0.1
  max_steps_multiplier: 4 # 4 * W * H

training:
  algo: "PPO"
  policy: "MultiInputPolicy" # Required for Dict observation
  total_timesteps: 100000
  learning_rate: 0.0003
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  
  # Checkpointing
  checkpoint_freq: 10000
  log_interval: 10

evaluation:
  eval_freq: 5000
  n_eval_episodes: 20
  benchmark_path: "configs/maps/benchmark_seeds.yaml" # Will be created
